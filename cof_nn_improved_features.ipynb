{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJPAsNItEJ11",
        "outputId": "9e267611-53bf-4b60-9a0c-2a6d578364cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.utils import normalize\n",
        "from keras.layers.advanced_activations import LeakyReLU"
      ],
      "metadata": {
        "id": "aHLjo2Y_ENs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = pd.read_csv(\"gdrive/My Drive/cofs/combined_features2.csv\")\n",
        "properties = pd.read_csv('gdrive/My Drive/cofs/properties.csv')"
      ],
      "metadata": {
        "id": "bYPyV65GEOnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# composition and structure to predict CO2Qst using NN\n",
        "\n",
        "x = features\n",
        "y = properties[\"CO2Qst_kJ_mol_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# from pervious HP training\n",
        "\n",
        "model_all_str_che = Sequential()\n",
        "model_all_str_che.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_all_str_che.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_all_str_che = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/all_str_che_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_all_str_che = model_all_str_che.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_all_str_che])"
      ],
      "metadata": {
        "id": "BWDP81-ZEjUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2042a6-bfa9-4590-948e-cdf12daf1992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 11s 7ms/step - loss: 19.3867 - val_loss: 6.7825\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 6s 6ms/step - loss: 5.9271 - val_loss: 5.7209\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 5.3049 - val_loss: 5.5049\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0077 - val_loss: 5.1495\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7863 - val_loss: 4.9091\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6097 - val_loss: 4.9420\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4429 - val_loss: 4.6751\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.3458 - val_loss: 4.5578\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.2392 - val_loss: 4.4786\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.1382 - val_loss: 4.5616\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.0672 - val_loss: 4.6881\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4.0057 - val_loss: 4.2810\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.8985 - val_loss: 4.4303\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.8590 - val_loss: 4.2330\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.7901 - val_loss: 4.3853\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.7640 - val_loss: 4.1456\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6952 - val_loss: 4.0847\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6395 - val_loss: 4.6288\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.5980 - val_loss: 4.0400\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.5539 - val_loss: 4.0503\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.5012 - val_loss: 4.0684\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.4675 - val_loss: 4.1409\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 3.4189 - val_loss: 3.9594\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.3589 - val_loss: 3.8770\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.3651 - val_loss: 4.1720\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 3.3064 - val_loss: 3.9875\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 3.2869 - val_loss: 3.7875\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.2344 - val_loss: 3.8329\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 3.2118 - val_loss: 3.7383\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.1714 - val_loss: 3.8761\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 3.1320 - val_loss: 3.7324\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.0984 - val_loss: 3.7185\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 3.0855 - val_loss: 3.6445\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.0382 - val_loss: 3.6350\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.0293 - val_loss: 3.6100\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3.0037 - val_loss: 3.6871\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.9647 - val_loss: 3.6658\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.9504 - val_loss: 3.6724\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.9131 - val_loss: 3.6015\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.9046 - val_loss: 3.6456\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8604 - val_loss: 3.9128\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.8655 - val_loss: 3.5674\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8245 - val_loss: 3.5598\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8200 - val_loss: 3.5805\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7971 - val_loss: 4.0186\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7790 - val_loss: 3.6935\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.7763 - val_loss: 3.5200\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7433 - val_loss: 3.4328\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7151 - val_loss: 3.5373\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.6872 - val_loss: 3.4538\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.6809 - val_loss: 3.6855\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 2.6587 - val_loss: 3.7285\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.6369 - val_loss: 3.5159\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.6473 - val_loss: 3.4856\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.6128 - val_loss: 3.4459\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.6369 - val_loss: 3.5962\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5779 - val_loss: 3.5069\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.5594 - val_loss: 3.4137\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5405 - val_loss: 3.4183\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5586 - val_loss: 3.4421\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5430 - val_loss: 3.4721\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5216 - val_loss: 3.4477\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4914 - val_loss: 3.4716\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4931 - val_loss: 3.4531\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4553 - val_loss: 3.4273\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4835 - val_loss: 3.5022\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.4491 - val_loss: 3.3475\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4474 - val_loss: 3.4050\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4239 - val_loss: 3.4413\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4190 - val_loss: 3.3721\n",
            "Epoch 71/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4120 - val_loss: 3.3512\n",
            "Epoch 72/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3992 - val_loss: 3.5069\n",
            "Epoch 73/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3856 - val_loss: 3.4945\n",
            "Epoch 74/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 2.3681 - val_loss: 3.3418\n",
            "Epoch 75/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3545 - val_loss: 3.3135\n",
            "Epoch 76/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3551 - val_loss: 3.3418\n",
            "Epoch 77/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3279 - val_loss: 3.6382\n",
            "Epoch 78/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.3265 - val_loss: 3.2809\n",
            "Epoch 79/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3245 - val_loss: 3.3487\n",
            "Epoch 80/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3111 - val_loss: 3.9364\n",
            "Epoch 81/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2843 - val_loss: 3.5590\n",
            "Epoch 82/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2945 - val_loss: 3.5833\n",
            "Epoch 83/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2640 - val_loss: 3.6540\n",
            "Epoch 84/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2628 - val_loss: 3.3093\n",
            "Epoch 85/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2385 - val_loss: 3.3387\n",
            "Epoch 86/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 2.2384 - val_loss: 3.2757\n",
            "Epoch 87/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.2340 - val_loss: 3.4288\n",
            "Epoch 88/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2200 - val_loss: 3.4206\n",
            "Epoch 89/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2227 - val_loss: 3.3435\n",
            "Epoch 90/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2297 - val_loss: 3.3020\n",
            "Epoch 91/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1895 - val_loss: 3.5033\n",
            "Epoch 92/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1884 - val_loss: 3.3577\n",
            "Epoch 93/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1773 - val_loss: 3.3446\n",
            "Epoch 94/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1779 - val_loss: 3.3782\n",
            "Epoch 95/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1339 - val_loss: 3.3413\n",
            "Epoch 96/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1395 - val_loss: 3.3328\n",
            "Epoch 97/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.1329 - val_loss: 3.2542\n",
            "Epoch 98/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1373 - val_loss: 3.5908\n",
            "Epoch 99/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1321 - val_loss: 3.4991\n",
            "Epoch 100/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 2.1167 - val_loss: 3.2416\n",
            "Epoch 101/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1122 - val_loss: 3.4627\n",
            "Epoch 102/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1203 - val_loss: 3.4644\n",
            "Epoch 103/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1069 - val_loss: 3.3103\n",
            "Epoch 104/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0718 - val_loss: 3.3574\n",
            "Epoch 105/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0875 - val_loss: 3.4208\n",
            "Epoch 106/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0828 - val_loss: 3.3096\n",
            "Epoch 107/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0660 - val_loss: 3.2761\n",
            "Epoch 108/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0453 - val_loss: 3.3411\n",
            "Epoch 109/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0399 - val_loss: 3.3687\n",
            "Epoch 110/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0507 - val_loss: 3.2889\n",
            "Epoch 111/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0512 - val_loss: 3.5068\n",
            "Epoch 112/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0155 - val_loss: 3.3711\n",
            "Epoch 113/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0337 - val_loss: 3.3327\n",
            "Epoch 114/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0372 - val_loss: 3.2431\n",
            "Epoch 115/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0078 - val_loss: 3.5505\n",
            "Epoch 116/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0199 - val_loss: 3.3880\n",
            "Epoch 117/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.9844 - val_loss: 3.2391\n",
            "Epoch 118/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.9731 - val_loss: 3.3198\n",
            "Epoch 119/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9762 - val_loss: 3.4751\n",
            "Epoch 120/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9580 - val_loss: 3.4588\n",
            "Epoch 121/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.9642 - val_loss: 3.2121\n",
            "Epoch 122/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9608 - val_loss: 3.2158\n",
            "Epoch 123/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9712 - val_loss: 3.2672\n",
            "Epoch 124/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9601 - val_loss: 3.5374\n",
            "Epoch 125/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9355 - val_loss: 3.2310\n",
            "Epoch 126/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9468 - val_loss: 3.2269\n",
            "Epoch 127/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9313 - val_loss: 3.2417\n",
            "Epoch 128/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9139 - val_loss: 3.7925\n",
            "Epoch 129/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9220 - val_loss: 3.4383\n",
            "Epoch 130/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8893 - val_loss: 3.3102\n",
            "Epoch 131/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.9240 - val_loss: 3.2092\n",
            "Epoch 132/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9290 - val_loss: 3.2679\n",
            "Epoch 133/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8929 - val_loss: 3.3381\n",
            "Epoch 134/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8857 - val_loss: 3.3087\n",
            "Epoch 135/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8874 - val_loss: 3.2247\n",
            "Epoch 136/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8833 - val_loss: 3.4435\n",
            "Epoch 137/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.8597 - val_loss: 3.1964\n",
            "Epoch 138/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8888 - val_loss: 3.3099\n",
            "Epoch 139/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8492 - val_loss: 3.2099\n",
            "Epoch 140/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8446 - val_loss: 3.3681\n",
            "Epoch 141/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8482 - val_loss: 3.3010\n",
            "Epoch 142/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8517 - val_loss: 3.6107\n",
            "Epoch 143/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8394 - val_loss: 3.2088\n",
            "Epoch 144/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8239 - val_loss: 3.2993\n",
            "Epoch 145/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8234 - val_loss: 3.2358\n",
            "Epoch 146/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 1.8156 - val_loss: 3.1943\n",
            "Epoch 147/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8151 - val_loss: 3.3181\n",
            "Epoch 148/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8122 - val_loss: 3.2514\n",
            "Epoch 149/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 1.8125 - val_loss: 3.7229\n",
            "Epoch 150/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.8030 - val_loss: 3.2224\n",
            "Epoch 151/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8276 - val_loss: 3.2837\n",
            "Epoch 152/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8020 - val_loss: 3.3479\n",
            "Epoch 153/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7789 - val_loss: 3.3531\n",
            "Epoch 154/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7795 - val_loss: 3.3938\n",
            "Epoch 155/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 1.7761 - val_loss: 3.1518\n",
            "Epoch 156/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7619 - val_loss: 3.3844\n",
            "Epoch 157/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7765 - val_loss: 3.1906\n",
            "Epoch 158/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7415 - val_loss: 3.2981\n",
            "Epoch 159/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7472 - val_loss: 3.4239\n",
            "Epoch 160/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7741 - val_loss: 3.3911\n",
            "Epoch 161/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7554 - val_loss: 3.4070\n",
            "Epoch 162/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7255 - val_loss: 3.4904\n",
            "Epoch 163/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7346 - val_loss: 3.2334\n",
            "Epoch 164/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7535 - val_loss: 3.3101\n",
            "Epoch 165/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7219 - val_loss: 3.3188\n",
            "Epoch 166/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7242 - val_loss: 3.4167\n",
            "Epoch 167/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7075 - val_loss: 3.2407\n",
            "Epoch 168/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6947 - val_loss: 3.2657\n",
            "Epoch 169/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7128 - val_loss: 3.2986\n",
            "Epoch 170/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6876 - val_loss: 3.2192\n",
            "Epoch 171/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.7103 - val_loss: 3.2821\n",
            "Epoch 172/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6949 - val_loss: 3.2521\n",
            "Epoch 173/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6999 - val_loss: 3.3229\n",
            "Epoch 174/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6676 - val_loss: 3.3703\n",
            "Epoch 175/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6699 - val_loss: 3.1775\n",
            "Epoch 176/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6771 - val_loss: 3.4379\n",
            "Epoch 177/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6740 - val_loss: 3.2863\n",
            "Epoch 178/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6659 - val_loss: 3.2306\n",
            "Epoch 179/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6532 - val_loss: 3.2329\n",
            "Epoch 180/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 1.6506 - val_loss: 3.3599\n",
            "Epoch 181/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 1.6599 - val_loss: 3.2993\n",
            "Epoch 182/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 1.6483 - val_loss: 3.4694\n",
            "Epoch 183/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6425 - val_loss: 3.3422\n",
            "Epoch 184/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6299 - val_loss: 3.2573\n",
            "Epoch 185/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6435 - val_loss: 3.2935\n",
            "Epoch 186/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6269 - val_loss: 3.4574\n",
            "Epoch 187/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6388 - val_loss: 3.2566\n",
            "Epoch 188/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6162 - val_loss: 3.4845\n",
            "Epoch 189/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6220 - val_loss: 3.2859\n",
            "Epoch 190/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5933 - val_loss: 3.1883\n",
            "Epoch 191/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6019 - val_loss: 3.3072\n",
            "Epoch 192/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5979 - val_loss: 3.1862\n",
            "Epoch 193/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6097 - val_loss: 3.6578\n",
            "Epoch 194/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5888 - val_loss: 3.4402\n",
            "Epoch 195/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5840 - val_loss: 3.2644\n",
            "Epoch 196/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5937 - val_loss: 3.3484\n",
            "Epoch 197/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5833 - val_loss: 3.3421\n",
            "Epoch 198/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 1.5704 - val_loss: 3.2022\n",
            "Epoch 199/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5750 - val_loss: 3.2728\n",
            "Epoch 200/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6029 - val_loss: 3.3714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_all_str_che.save(\"all_str_che_co2q.h5\")\n",
        "\n",
        "model_all_str_che.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_all_str_che.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "uKCOPfnaKDQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df84f3e7-a579-4476-c5a3-7f3518f8576f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "468/468 [==============================] - 1s 2ms/step - loss: 3.5225\n",
            "R^2: 0.8252941106549926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition and structure to predict CO2Qst using NN\n",
        "\n",
        "x = features\n",
        "y = properties[\"absoluteMethaneUptakeHighP_mol_kg_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# from pervious HP training\n",
        "\n",
        "model_all_str_che_ch4 = Sequential()\n",
        "model_all_str_che_ch4.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_ch4.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_ch4.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_all_str_che_ch4.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_all_str_che_ch4 = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/all_str_che_ch4.h5\", save_best_only = True)\n",
        "\n",
        "fit_all_str_che_ch4 = model_all_str_che_ch4.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_all_str_che_ch4])\n",
        "\n",
        "model_all_str_che_ch4.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_all_str_che_ch4.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "A3lSBzj6HiSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3ebe9c-ee32-4403-92c7-2a4c5dfa2aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 71.8514 - val_loss: 8.8379\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9480 - val_loss: 2.7305\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8767 - val_loss: 1.6928\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.2401 - val_loss: 1.1659\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 1.0263 - val_loss: 1.1467\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.9171 - val_loss: 0.9617\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.8366 - val_loss: 0.8797\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.7621 - val_loss: 0.7441\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.7128 - val_loss: 0.7122\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6776 - val_loss: 0.7936\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6336 - val_loss: 0.6640\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6300 - val_loss: 0.6274\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6023 - val_loss: 0.6565\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5816 - val_loss: 0.6434\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5683 - val_loss: 0.6275\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5571 - val_loss: 0.6897\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5399 - val_loss: 0.6589\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.5414 - val_loss: 0.5895\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5097 - val_loss: 0.5733\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5093 - val_loss: 0.5734\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.5073 - val_loss: 0.5825\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4788 - val_loss: 0.5992\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4748 - val_loss: 0.6070\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.4733 - val_loss: 0.5323\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4529 - val_loss: 0.6260\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4584 - val_loss: 0.6786\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.4444 - val_loss: 0.5313\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4420 - val_loss: 0.5130\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.4376 - val_loss: 0.5671\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4263 - val_loss: 0.5405\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4202 - val_loss: 0.5173\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.4276 - val_loss: 0.4950\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4066 - val_loss: 0.6664\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4053 - val_loss: 0.5599\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4015 - val_loss: 0.5458\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3909 - val_loss: 0.5024\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4030 - val_loss: 0.5021\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3911 - val_loss: 0.5378\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3888 - val_loss: 0.5287\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.3799 - val_loss: 0.4746\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3825 - val_loss: 0.5912\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3755 - val_loss: 0.5083\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3726 - val_loss: 0.4844\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.3733 - val_loss: 0.4514\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3698 - val_loss: 0.4715\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3646 - val_loss: 0.5973\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3622 - val_loss: 0.5773\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3522 - val_loss: 0.5102\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3597 - val_loss: 0.4786\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3530 - val_loss: 0.7264\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3486 - val_loss: 0.4706\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3427 - val_loss: 0.4688\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3452 - val_loss: 0.4605\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3318 - val_loss: 0.4625\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3438 - val_loss: 0.4664\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3313 - val_loss: 0.5184\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3321 - val_loss: 0.5361\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3304 - val_loss: 0.4670\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3286 - val_loss: 0.4985\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.3250 - val_loss: 0.4654\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.3254 - val_loss: 0.4751\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3224 - val_loss: 0.4850\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3160 - val_loss: 0.4942\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3174 - val_loss: 0.6273\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.3103 - val_loss: 0.4392\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3139 - val_loss: 0.4832\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3138 - val_loss: 0.4242\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3104 - val_loss: 0.4665\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3053 - val_loss: 0.4548\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3023 - val_loss: 0.4462\n",
            "Epoch 71/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3067 - val_loss: 0.4461\n",
            "Epoch 72/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2986 - val_loss: 0.4616\n",
            "Epoch 73/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3001 - val_loss: 0.4355\n",
            "Epoch 74/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2999 - val_loss: 0.4192\n",
            "Epoch 75/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2945 - val_loss: 0.4522\n",
            "Epoch 76/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2918 - val_loss: 0.4623\n",
            "Epoch 77/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2967 - val_loss: 0.4301\n",
            "Epoch 78/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2897 - val_loss: 0.4455\n",
            "Epoch 79/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2870 - val_loss: 0.4520\n",
            "Epoch 80/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2895 - val_loss: 0.4325\n",
            "Epoch 81/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2912 - val_loss: 0.5031\n",
            "Epoch 82/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2761 - val_loss: 0.4984\n",
            "Epoch 83/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2821 - val_loss: 0.4663\n",
            "Epoch 84/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2862 - val_loss: 0.5794\n",
            "Epoch 85/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2740 - val_loss: 0.4254\n",
            "Epoch 86/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2815 - val_loss: 0.4128\n",
            "Epoch 87/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2673 - val_loss: 0.4297\n",
            "Epoch 88/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2800 - val_loss: 0.4964\n",
            "Epoch 89/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2732 - val_loss: 0.4265\n",
            "Epoch 90/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2764 - val_loss: 0.4495\n",
            "Epoch 91/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2678 - val_loss: 0.4368\n",
            "Epoch 92/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2737 - val_loss: 0.4143\n",
            "Epoch 93/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2717 - val_loss: 0.4172\n",
            "Epoch 94/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2611 - val_loss: 0.4223\n",
            "Epoch 95/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2679 - val_loss: 0.4509\n",
            "Epoch 96/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2667 - val_loss: 0.4775\n",
            "Epoch 97/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2563 - val_loss: 0.4526\n",
            "Epoch 98/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2604 - val_loss: 0.3926\n",
            "Epoch 99/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2600 - val_loss: 0.4135\n",
            "Epoch 100/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2597 - val_loss: 0.4586\n",
            "Epoch 101/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2604 - val_loss: 0.4115\n",
            "Epoch 102/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2529 - val_loss: 0.3992\n",
            "Epoch 103/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2525 - val_loss: 0.4549\n",
            "Epoch 104/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2535 - val_loss: 0.4175\n",
            "Epoch 105/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2447 - val_loss: 0.4422\n",
            "Epoch 106/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2568 - val_loss: 0.4328\n",
            "Epoch 107/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2486 - val_loss: 0.5048\n",
            "Epoch 108/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2475 - val_loss: 0.3938\n",
            "Epoch 109/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2452 - val_loss: 0.4569\n",
            "Epoch 110/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2434 - val_loss: 0.4034\n",
            "Epoch 111/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2426 - val_loss: 0.5221\n",
            "Epoch 112/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2470 - val_loss: 0.3856\n",
            "Epoch 113/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2452 - val_loss: 0.4004\n",
            "Epoch 114/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2384 - val_loss: 0.4092\n",
            "Epoch 115/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2409 - val_loss: 0.4105\n",
            "Epoch 116/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2361 - val_loss: 0.4388\n",
            "Epoch 117/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2404 - val_loss: 0.4342\n",
            "Epoch 118/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2351 - val_loss: 0.4017\n",
            "Epoch 119/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2348 - val_loss: 0.4092\n",
            "Epoch 120/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2352 - val_loss: 0.3776\n",
            "Epoch 121/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2411 - val_loss: 0.4079\n",
            "Epoch 122/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2319 - val_loss: 0.3990\n",
            "Epoch 123/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.2301 - val_loss: 0.4794\n",
            "Epoch 124/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2302 - val_loss: 0.4092\n",
            "Epoch 125/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2281 - val_loss: 0.4115\n",
            "Epoch 126/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2313 - val_loss: 0.3878\n",
            "Epoch 127/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2237 - val_loss: 0.4453\n",
            "Epoch 128/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2280 - val_loss: 0.4220\n",
            "Epoch 129/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2254 - val_loss: 0.3982\n",
            "Epoch 130/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2241 - val_loss: 0.4021\n",
            "Epoch 131/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2277 - val_loss: 0.4054\n",
            "Epoch 132/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2224 - val_loss: 0.4657\n",
            "Epoch 133/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2260 - val_loss: 0.3883\n",
            "Epoch 134/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2253 - val_loss: 0.3857\n",
            "Epoch 135/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.2225 - val_loss: 0.4459\n",
            "Epoch 136/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2207 - val_loss: 0.4445\n",
            "Epoch 137/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2203 - val_loss: 0.4449\n",
            "Epoch 138/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2226 - val_loss: 0.3985\n",
            "Epoch 139/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2163 - val_loss: 0.3927\n",
            "Epoch 140/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2153 - val_loss: 0.4502\n",
            "Epoch 141/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2191 - val_loss: 0.4012\n",
            "Epoch 142/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2187 - val_loss: 0.3835\n",
            "Epoch 143/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2119 - val_loss: 0.3966\n",
            "Epoch 144/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2131 - val_loss: 0.3897\n",
            "Epoch 145/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2117 - val_loss: 0.3922\n",
            "Epoch 146/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2101 - val_loss: 0.3788\n",
            "Epoch 147/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2153 - val_loss: 0.4329\n",
            "Epoch 148/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2093 - val_loss: 0.4157\n",
            "Epoch 149/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2114 - val_loss: 0.5684\n",
            "Epoch 150/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.2107 - val_loss: 0.3718\n",
            "Epoch 151/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2120 - val_loss: 0.4154\n",
            "Epoch 152/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2003 - val_loss: 0.3800\n",
            "Epoch 153/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2029 - val_loss: 0.3732\n",
            "Epoch 154/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2055 - val_loss: 0.3937\n",
            "Epoch 155/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 0.2105 - val_loss: 0.3728\n",
            "Epoch 156/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2070 - val_loss: 0.3961\n",
            "Epoch 157/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2058 - val_loss: 0.3843\n",
            "Epoch 158/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2028 - val_loss: 0.4084\n",
            "Epoch 159/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.2054 - val_loss: 0.3674\n",
            "Epoch 160/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2044 - val_loss: 0.4450\n",
            "Epoch 161/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2044 - val_loss: 0.4159\n",
            "Epoch 162/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1998 - val_loss: 0.3878\n",
            "Epoch 163/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2004 - val_loss: 0.3781\n",
            "Epoch 164/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2087 - val_loss: 0.3957\n",
            "Epoch 165/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1965 - val_loss: 0.3720\n",
            "Epoch 166/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2025 - val_loss: 0.3850\n",
            "Epoch 167/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2020 - val_loss: 0.4599\n",
            "Epoch 168/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1947 - val_loss: 0.3900\n",
            "Epoch 169/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2057 - val_loss: 0.3931\n",
            "Epoch 170/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1930 - val_loss: 0.3911\n",
            "Epoch 171/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1985 - val_loss: 0.3892\n",
            "Epoch 172/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1951 - val_loss: 0.4091\n",
            "Epoch 173/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1940 - val_loss: 0.3847\n",
            "Epoch 174/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1983 - val_loss: 0.3729\n",
            "Epoch 175/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1941 - val_loss: 0.3763\n",
            "Epoch 176/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1916 - val_loss: 0.4169\n",
            "Epoch 177/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1947 - val_loss: 0.3845\n",
            "Epoch 178/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1901 - val_loss: 0.3873\n",
            "Epoch 179/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1928 - val_loss: 0.3839\n",
            "Epoch 180/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1895 - val_loss: 0.4133\n",
            "Epoch 181/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1893 - val_loss: 0.3713\n",
            "Epoch 182/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1930 - val_loss: 0.3836\n",
            "Epoch 183/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1884 - val_loss: 0.3735\n",
            "Epoch 184/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1907 - val_loss: 0.3992\n",
            "Epoch 185/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1896 - val_loss: 0.4325\n",
            "Epoch 186/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 0.1863 - val_loss: 0.3730\n",
            "Epoch 187/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1898 - val_loss: 0.3732\n",
            "Epoch 188/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.1815 - val_loss: 0.3644\n",
            "Epoch 189/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1852 - val_loss: 0.3777\n",
            "Epoch 190/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1884 - val_loss: 0.3901\n",
            "Epoch 191/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1900 - val_loss: 0.3988\n",
            "Epoch 192/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1856 - val_loss: 0.4211\n",
            "Epoch 193/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1832 - val_loss: 0.3946\n",
            "Epoch 194/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1844 - val_loss: 0.4309\n",
            "Epoch 195/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1863 - val_loss: 0.3671\n",
            "Epoch 196/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1818 - val_loss: 0.3665\n",
            "Epoch 197/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1818 - val_loss: 0.3795\n",
            "Epoch 198/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 0.1849 - val_loss: 0.4131\n",
            "Epoch 199/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1820 - val_loss: 0.3889\n",
            "Epoch 200/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1822 - val_loss: 0.3917\n",
            "468/468 [==============================] - 1s 2ms/step - loss: 0.4302\n",
            "R^2: 0.9962643707820079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict CO2Qst\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y = properties[\"CO2Qst_kJ_mol_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_only = Sequential()\n",
        "model_che_only.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_only.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_only.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_only.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_che_only = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_only_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_only = model_che_only.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_only])"
      ],
      "metadata": {
        "id": "_nQRxovKHQhs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d1ffb0-5438-4f73-a4f8-c0531d02316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 24.9820 - val_loss: 14.0710\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 13.2763 - val_loss: 13.1750\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 12.7417 - val_loss: 12.8210\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 12.3248 - val_loss: 12.4853\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 12.0666 - val_loss: 12.2478\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 11.7691 - val_loss: 12.4170\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 11.5942 - val_loss: 11.8723\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 11.4354 - val_loss: 12.4355\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 11.2068 - val_loss: 11.8262\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 11.0632 - val_loss: 11.5563\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.9300 - val_loss: 11.7099\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.8315 - val_loss: 11.4378\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 10.6838 - val_loss: 11.4752\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 10.6113 - val_loss: 11.3077\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.4997 - val_loss: 11.1287\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.4020 - val_loss: 11.0810\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.3724 - val_loss: 11.0208\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.2546 - val_loss: 11.0780\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.1834 - val_loss: 10.9727\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.1251 - val_loss: 11.0687\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.0543 - val_loss: 11.0594\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 10.0045 - val_loss: 11.0065\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 9.9004 - val_loss: 10.9479\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.8703 - val_loss: 11.6709\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.8793 - val_loss: 10.8460\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.7509 - val_loss: 10.9628\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.6824 - val_loss: 10.7970\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.6438 - val_loss: 10.8340\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.6104 - val_loss: 10.8265\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 9.5889 - val_loss: 10.7662\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 9.5316 - val_loss: 10.7368\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.4791 - val_loss: 10.6732\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.4624 - val_loss: 10.8677\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.4121 - val_loss: 10.8856\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.3719 - val_loss: 10.6884\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 9.3487 - val_loss: 10.5784\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.2706 - val_loss: 10.7687\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.2505 - val_loss: 10.7828\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.2512 - val_loss: 10.6313\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.1857 - val_loss: 10.6086\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.1702 - val_loss: 10.6398\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.1033 - val_loss: 10.6691\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.0767 - val_loss: 10.6533\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 9.0741 - val_loss: 10.7232\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.0348 - val_loss: 10.7225\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 9.0027 - val_loss: 11.1189\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.9521 - val_loss: 10.9425\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.9599 - val_loss: 10.6756\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.9270 - val_loss: 10.8580\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.9038 - val_loss: 10.6681\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.8641 - val_loss: 10.8281\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.8854 - val_loss: 10.6361\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.8440 - val_loss: 10.7147\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7849 - val_loss: 10.5928\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7964 - val_loss: 10.7558\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7507 - val_loss: 10.8386\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7160 - val_loss: 10.8171\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7466 - val_loss: 10.9499\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7044 - val_loss: 10.8347\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.6615 - val_loss: 10.8610\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 8.6507 - val_loss: 10.5346\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.6428 - val_loss: 10.9385\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.6197 - val_loss: 10.8305\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5958 - val_loss: 10.8471\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5729 - val_loss: 10.5898\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5605 - val_loss: 10.6631\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5765 - val_loss: 10.8756\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5735 - val_loss: 10.7414\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5216 - val_loss: 11.0808\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.4959 - val_loss: 10.8899\n",
            "Epoch 71/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.4891 - val_loss: 10.5869\n",
            "Epoch 72/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 8.4609 - val_loss: 10.4982\n",
            "Epoch 73/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.4156 - val_loss: 10.6248\n",
            "Epoch 74/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.4600 - val_loss: 10.6547\n",
            "Epoch 75/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 8.3771 - val_loss: 10.8208\n",
            "Epoch 76/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 8.4058 - val_loss: 10.6147\n",
            "Epoch 77/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3565 - val_loss: 10.6870\n",
            "Epoch 78/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3731 - val_loss: 10.6594\n",
            "Epoch 79/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3922 - val_loss: 10.8067\n",
            "Epoch 80/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3440 - val_loss: 10.7026\n",
            "Epoch 81/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3096 - val_loss: 11.2335\n",
            "Epoch 82/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3201 - val_loss: 10.6070\n",
            "Epoch 83/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.2989 - val_loss: 10.8418\n",
            "Epoch 84/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3085 - val_loss: 10.5808\n",
            "Epoch 85/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.2842 - val_loss: 10.7174\n",
            "Epoch 86/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.2474 - val_loss: 10.8338\n",
            "Epoch 87/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.2774 - val_loss: 10.6129\n",
            "Epoch 88/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1922 - val_loss: 10.8241\n",
            "Epoch 89/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.2352 - val_loss: 10.7452\n",
            "Epoch 90/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1826 - val_loss: 10.5821\n",
            "Epoch 91/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1687 - val_loss: 10.9374\n",
            "Epoch 92/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1530 - val_loss: 10.5732\n",
            "Epoch 93/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1649 - val_loss: 10.7062\n",
            "Epoch 94/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1724 - val_loss: 10.5981\n",
            "Epoch 95/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1561 - val_loss: 10.7909\n",
            "Epoch 96/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1346 - val_loss: 10.9320\n",
            "Epoch 97/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0994 - val_loss: 10.7088\n",
            "Epoch 98/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1388 - val_loss: 10.6229\n",
            "Epoch 99/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0807 - val_loss: 10.6877\n",
            "Epoch 100/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.1050 - val_loss: 10.8154\n",
            "Epoch 101/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0827 - val_loss: 10.6824\n",
            "Epoch 102/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0433 - val_loss: 10.6081\n",
            "Epoch 103/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0430 - val_loss: 10.9830\n",
            "Epoch 104/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0541 - val_loss: 10.7196\n",
            "Epoch 105/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0074 - val_loss: 10.8016\n",
            "Epoch 106/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9944 - val_loss: 10.7168\n",
            "Epoch 107/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 7.9810 - val_loss: 10.9952\n",
            "Epoch 108/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0354 - val_loss: 10.7808\n",
            "Epoch 109/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9627 - val_loss: 10.7572\n",
            "Epoch 110/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9785 - val_loss: 10.7537\n",
            "Epoch 111/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9609 - val_loss: 10.6503\n",
            "Epoch 112/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9423 - val_loss: 10.8622\n",
            "Epoch 113/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9555 - val_loss: 11.0185\n",
            "Epoch 114/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9309 - val_loss: 10.7435\n",
            "Epoch 115/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9194 - val_loss: 10.7091\n",
            "Epoch 116/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9379 - val_loss: 10.6739\n",
            "Epoch 117/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9012 - val_loss: 10.5661\n",
            "Epoch 118/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8957 - val_loss: 10.6140\n",
            "Epoch 119/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8965 - val_loss: 10.7286\n",
            "Epoch 120/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8660 - val_loss: 10.6312\n",
            "Epoch 121/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.9027 - val_loss: 10.6637\n",
            "Epoch 122/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8753 - val_loss: 11.0949\n",
            "Epoch 123/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8156 - val_loss: 10.6615\n",
            "Epoch 124/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8650 - val_loss: 10.7190\n",
            "Epoch 125/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8094 - val_loss: 10.7684\n",
            "Epoch 126/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7782 - val_loss: 10.8933\n",
            "Epoch 127/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8163 - val_loss: 10.6830\n",
            "Epoch 128/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7742 - val_loss: 10.7913\n",
            "Epoch 129/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7534 - val_loss: 10.7482\n",
            "Epoch 130/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7745 - val_loss: 10.8333\n",
            "Epoch 131/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7514 - val_loss: 10.8053\n",
            "Epoch 132/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7742 - val_loss: 10.9154\n",
            "Epoch 133/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7631 - val_loss: 10.6086\n",
            "Epoch 134/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7313 - val_loss: 10.6605\n",
            "Epoch 135/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7506 - val_loss: 10.7958\n",
            "Epoch 136/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7247 - val_loss: 10.7377\n",
            "Epoch 137/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6813 - val_loss: 10.7211\n",
            "Epoch 138/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7067 - val_loss: 10.9944\n",
            "Epoch 139/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 7.7281 - val_loss: 10.8615\n",
            "Epoch 140/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 7.6657 - val_loss: 10.9994\n",
            "Epoch 141/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 7.7175 - val_loss: 10.6553\n",
            "Epoch 142/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6700 - val_loss: 10.6697\n",
            "Epoch 143/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6687 - val_loss: 10.9544\n",
            "Epoch 144/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6403 - val_loss: 11.4168\n",
            "Epoch 145/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6394 - val_loss: 10.8105\n",
            "Epoch 146/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6677 - val_loss: 11.2182\n",
            "Epoch 147/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6509 - val_loss: 11.1019\n",
            "Epoch 148/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6328 - val_loss: 10.7136\n",
            "Epoch 149/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6135 - val_loss: 10.9014\n",
            "Epoch 150/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 7.6454 - val_loss: 10.8455\n",
            "Epoch 151/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5691 - val_loss: 11.0693\n",
            "Epoch 152/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6066 - val_loss: 10.7914\n",
            "Epoch 153/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6026 - val_loss: 10.8455\n",
            "Epoch 154/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6088 - val_loss: 10.7313\n",
            "Epoch 155/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5733 - val_loss: 11.0289\n",
            "Epoch 156/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5902 - val_loss: 11.0626\n",
            "Epoch 157/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5686 - val_loss: 11.2100\n",
            "Epoch 158/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5713 - val_loss: 10.9007\n",
            "Epoch 159/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5302 - val_loss: 10.7097\n",
            "Epoch 160/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5593 - val_loss: 10.7957\n",
            "Epoch 161/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5128 - val_loss: 11.0880\n",
            "Epoch 162/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5269 - val_loss: 10.9171\n",
            "Epoch 163/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5011 - val_loss: 10.8784\n",
            "Epoch 164/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5143 - val_loss: 10.9305\n",
            "Epoch 165/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4954 - val_loss: 10.9066\n",
            "Epoch 166/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4986 - val_loss: 11.2922\n",
            "Epoch 167/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.5121 - val_loss: 10.7215\n",
            "Epoch 168/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4739 - val_loss: 11.0184\n",
            "Epoch 169/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4704 - val_loss: 10.8772\n",
            "Epoch 170/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4897 - val_loss: 11.0353\n",
            "Epoch 171/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 7.4497 - val_loss: 10.9353\n",
            "Epoch 172/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4720 - val_loss: 10.9084\n",
            "Epoch 173/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4555 - val_loss: 10.8901\n",
            "Epoch 174/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4472 - val_loss: 10.9706\n",
            "Epoch 175/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4207 - val_loss: 10.9750\n",
            "Epoch 176/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4115 - val_loss: 11.1354\n",
            "Epoch 177/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4349 - val_loss: 11.0038\n",
            "Epoch 178/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4313 - val_loss: 10.8877\n",
            "Epoch 179/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4015 - val_loss: 11.0264\n",
            "Epoch 180/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3800 - val_loss: 11.2441\n",
            "Epoch 181/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3873 - val_loss: 11.0550\n",
            "Epoch 182/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3675 - val_loss: 10.8172\n",
            "Epoch 183/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3911 - val_loss: 11.0334\n",
            "Epoch 184/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3775 - val_loss: 11.0012\n",
            "Epoch 185/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3786 - val_loss: 11.0016\n",
            "Epoch 186/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3694 - val_loss: 11.4405\n",
            "Epoch 187/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3256 - val_loss: 12.0878\n",
            "Epoch 188/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3477 - val_loss: 11.0269\n",
            "Epoch 189/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3369 - val_loss: 11.1560\n",
            "Epoch 190/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3612 - val_loss: 11.1705\n",
            "Epoch 191/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3357 - val_loss: 10.9032\n",
            "Epoch 192/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2811 - val_loss: 11.0996\n",
            "Epoch 193/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3026 - val_loss: 10.9770\n",
            "Epoch 194/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3525 - val_loss: 11.0098\n",
            "Epoch 195/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2995 - val_loss: 11.1034\n",
            "Epoch 196/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2908 - val_loss: 11.1285\n",
            "Epoch 197/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3196 - val_loss: 10.9733\n",
            "Epoch 198/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2889 - val_loss: 10.9671\n",
            "Epoch 199/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2571 - val_loss: 10.9736\n",
            "Epoch 200/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3027 - val_loss: 11.0663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_che_only.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_only.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "-HwoDGdOIr2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6398d2-f088-4e46-ef87-3d4187d2034c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "468/468 [==============================] - 1s 2ms/step - loss: 11.2046\n",
            "R^2: 0.4442887201612413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict structural features\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y_dens = features[\"density_kg_m_3_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_dens, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_pred_dens = Sequential()\n",
        "model_che_pred_dens.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_dens.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_dens.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_pred_dens.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_che_pred_dens = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_pred_dens_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_pred_dens = model_che_pred_dens.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_pred_dens])"
      ],
      "metadata": {
        "id": "F8NNDs4rKhJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70e2ded-8e65-4462-80a1-38673790b28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 15840.7520 - val_loss: 8586.1973\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 7547.1841 - val_loss: 7254.2915\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 6880.2529 - val_loss: 6867.7446\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 6596.7827 - val_loss: 6637.6665\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 6398.6440 - val_loss: 6492.2959\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 6234.4043 - val_loss: 6340.1714\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 6100.5801 - val_loss: 6214.8701\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5984.4341 - val_loss: 6191.2402\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5873.2153 - val_loss: 6118.3281\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5773.3818 - val_loss: 5966.3677\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5684.3325 - val_loss: 5875.7192\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5593.8711 - val_loss: 5821.3892\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5512.5815 - val_loss: 5736.0381\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5447.4805 - val_loss: 5692.2471\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5377.2988 - val_loss: 5757.3867\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5350.9209 - val_loss: 5637.1538\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5286.7104 - val_loss: 5580.6489\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5230.7705 - val_loss: 5562.5815\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5191.4858 - val_loss: 5516.4810\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5170.5156 - val_loss: 5472.1660\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5120.7056 - val_loss: 5412.6675\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5082.4722 - val_loss: 5615.2192\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5049.5571 - val_loss: 5389.5962\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5036.6475 - val_loss: 5442.3350\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4980.4170 - val_loss: 5376.3345\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4948.1060 - val_loss: 5408.4009\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4942.1655 - val_loss: 5351.8877\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4903.3726 - val_loss: 5272.2744\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4866.4185 - val_loss: 5308.1577\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4842.5415 - val_loss: 5251.6792\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4826.8926 - val_loss: 5212.4233\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4791.3613 - val_loss: 5229.1284\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4764.8647 - val_loss: 5323.6240\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4740.8955 - val_loss: 5346.7285\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4721.9736 - val_loss: 5163.4541\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4699.8354 - val_loss: 5152.2148\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4661.4541 - val_loss: 5134.2607\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4649.6587 - val_loss: 5120.8296\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4634.3525 - val_loss: 5268.0454\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4605.6831 - val_loss: 5119.6133\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4581.6553 - val_loss: 5153.8818\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4572.8062 - val_loss: 5091.3193\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4553.4478 - val_loss: 5129.1870\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4531.6880 - val_loss: 5044.9761\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4503.3955 - val_loss: 5031.6201\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4484.5337 - val_loss: 5055.2334\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4470.9165 - val_loss: 5101.0527\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4458.9683 - val_loss: 5039.9087\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4442.5791 - val_loss: 5043.8184\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4432.5249 - val_loss: 5044.2666\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4390.8057 - val_loss: 5016.8691\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4389.6504 - val_loss: 5047.1372\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4382.7910 - val_loss: 5032.8848\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4358.1338 - val_loss: 5012.2949\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4343.3706 - val_loss: 4971.5762\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4335.6738 - val_loss: 5120.8569\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4315.8511 - val_loss: 4949.4565\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4304.3657 - val_loss: 5101.8799\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4296.6191 - val_loss: 5024.5850\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4277.7710 - val_loss: 5031.2417\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4277.6021 - val_loss: 5227.0259\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4272.9678 - val_loss: 5081.7256\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4257.8623 - val_loss: 5002.1758\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4254.0698 - val_loss: 5011.4800\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4246.7749 - val_loss: 4959.5093\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4223.3296 - val_loss: 5041.6191\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4219.8589 - val_loss: 4976.0605\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4211.5425 - val_loss: 4961.9351\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4208.7217 - val_loss: 5032.8042\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4207.1963 - val_loss: 4957.5576\n",
            "Epoch 71/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4177.5483 - val_loss: 4934.3989\n",
            "Epoch 72/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4175.0752 - val_loss: 4981.4448\n",
            "Epoch 73/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4180.9067 - val_loss: 4958.8696\n",
            "Epoch 74/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4163.1997 - val_loss: 4887.8467\n",
            "Epoch 75/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4151.5601 - val_loss: 5019.3701\n",
            "Epoch 76/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4155.5649 - val_loss: 4977.8032\n",
            "Epoch 77/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4142.8511 - val_loss: 4939.8745\n",
            "Epoch 78/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4154.3325 - val_loss: 4939.3643\n",
            "Epoch 79/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4118.0024 - val_loss: 4921.6504\n",
            "Epoch 80/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4126.5938 - val_loss: 4968.7236\n",
            "Epoch 81/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4113.7388 - val_loss: 4944.3013\n",
            "Epoch 82/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4107.2241 - val_loss: 4928.9170\n",
            "Epoch 83/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4097.6616 - val_loss: 5125.8452\n",
            "Epoch 84/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4099.6753 - val_loss: 4997.5659\n",
            "Epoch 85/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4091.6672 - val_loss: 5011.7192\n",
            "Epoch 86/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4082.4500 - val_loss: 4941.2085\n",
            "Epoch 87/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4083.1006 - val_loss: 4947.2007\n",
            "Epoch 88/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4075.8545 - val_loss: 4984.3477\n",
            "Epoch 89/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4075.3887 - val_loss: 4984.9180\n",
            "Epoch 90/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4061.2952 - val_loss: 5052.0552\n",
            "Epoch 91/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4066.7422 - val_loss: 4985.6562\n",
            "Epoch 92/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4060.6787 - val_loss: 5050.6851\n",
            "Epoch 93/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4057.3413 - val_loss: 4970.1919\n",
            "Epoch 94/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4050.2957 - val_loss: 4932.4102\n",
            "Epoch 95/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4041.3301 - val_loss: 4978.3301\n",
            "Epoch 96/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4031.2476 - val_loss: 4996.9189\n",
            "Epoch 97/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4030.7959 - val_loss: 4966.0186\n",
            "Epoch 98/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4034.3254 - val_loss: 4976.0381\n",
            "Epoch 99/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4019.4644 - val_loss: 5014.9146\n",
            "Epoch 100/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4020.4514 - val_loss: 5015.1357\n",
            "Epoch 101/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4022.9436 - val_loss: 4887.0820\n",
            "Epoch 102/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4020.1492 - val_loss: 5031.2319\n",
            "Epoch 103/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4010.3308 - val_loss: 4919.0947\n",
            "Epoch 104/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3998.7627 - val_loss: 5001.8857\n",
            "Epoch 105/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3997.6799 - val_loss: 5050.7280\n",
            "Epoch 106/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3991.3696 - val_loss: 4946.2778\n",
            "Epoch 107/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3984.1226 - val_loss: 5084.5571\n",
            "Epoch 108/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3986.9727 - val_loss: 4972.5513\n",
            "Epoch 109/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3974.8513 - val_loss: 5090.9844\n",
            "Epoch 110/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3986.2444 - val_loss: 4983.6362\n",
            "Epoch 111/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3978.0237 - val_loss: 5032.1680\n",
            "Epoch 112/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3971.7617 - val_loss: 5017.8984\n",
            "Epoch 113/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3971.3918 - val_loss: 4962.2856\n",
            "Epoch 114/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3968.8611 - val_loss: 4971.4214\n",
            "Epoch 115/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3962.9165 - val_loss: 4992.5088\n",
            "Epoch 116/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3964.4465 - val_loss: 5023.1274\n",
            "Epoch 117/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3950.6150 - val_loss: 5007.1104\n",
            "Epoch 118/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3943.0764 - val_loss: 5008.0029\n",
            "Epoch 119/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3951.2314 - val_loss: 5010.0850\n",
            "Epoch 120/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3944.2197 - val_loss: 5034.7705\n",
            "Epoch 121/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3949.2769 - val_loss: 5047.7339\n",
            "Epoch 122/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3941.9246 - val_loss: 5011.5054\n",
            "Epoch 123/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3929.6929 - val_loss: 5000.8535\n",
            "Epoch 124/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3918.6191 - val_loss: 4941.0898\n",
            "Epoch 125/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3929.4937 - val_loss: 5014.7246\n",
            "Epoch 126/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3912.4907 - val_loss: 5036.3145\n",
            "Epoch 127/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 3917.4905 - val_loss: 4936.0728\n",
            "Epoch 128/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3914.6758 - val_loss: 5057.2827\n",
            "Epoch 129/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3917.1245 - val_loss: 5028.0781\n",
            "Epoch 130/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3921.3699 - val_loss: 5001.6836\n",
            "Epoch 131/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3910.6711 - val_loss: 5009.4312\n",
            "Epoch 132/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3908.0586 - val_loss: 5093.4600\n",
            "Epoch 133/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3902.6365 - val_loss: 4966.8369\n",
            "Epoch 134/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3907.4788 - val_loss: 4999.6445\n",
            "Epoch 135/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3902.8972 - val_loss: 5013.5103\n",
            "Epoch 136/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3903.7236 - val_loss: 5079.8062\n",
            "Epoch 137/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3899.1902 - val_loss: 5063.3784\n",
            "Epoch 138/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3894.9248 - val_loss: 5011.1440\n",
            "Epoch 139/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3871.8784 - val_loss: 4984.8047\n",
            "Epoch 140/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3877.6289 - val_loss: 5067.3135\n",
            "Epoch 141/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3883.0798 - val_loss: 4966.4790\n",
            "Epoch 142/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3875.4421 - val_loss: 5019.6001\n",
            "Epoch 143/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3894.6602 - val_loss: 5065.8052\n",
            "Epoch 144/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3882.1204 - val_loss: 5059.6768\n",
            "Epoch 145/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3865.6057 - val_loss: 5136.6167\n",
            "Epoch 146/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3861.4685 - val_loss: 5047.7754\n",
            "Epoch 147/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3869.6816 - val_loss: 5008.1494\n",
            "Epoch 148/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3862.2861 - val_loss: 5047.7798\n",
            "Epoch 149/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3849.4590 - val_loss: 4999.4482\n",
            "Epoch 150/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3857.0559 - val_loss: 5054.9634\n",
            "Epoch 151/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3856.8535 - val_loss: 5089.8940\n",
            "Epoch 152/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3855.0898 - val_loss: 5082.2837\n",
            "Epoch 153/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3853.2854 - val_loss: 5006.8174\n",
            "Epoch 154/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3842.1406 - val_loss: 5177.1958\n",
            "Epoch 155/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3856.7849 - val_loss: 5124.7949\n",
            "Epoch 156/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3839.2644 - val_loss: 5024.5923\n",
            "Epoch 157/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3845.3577 - val_loss: 5009.5317\n",
            "Epoch 158/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3839.0122 - val_loss: 5019.5332\n",
            "Epoch 159/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 3831.9141 - val_loss: 5057.9722\n",
            "Epoch 160/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3833.8110 - val_loss: 5042.9678\n",
            "Epoch 161/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3825.2678 - val_loss: 5232.5894\n",
            "Epoch 162/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3833.1125 - val_loss: 5100.4819\n",
            "Epoch 163/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3828.1233 - val_loss: 5193.5435\n",
            "Epoch 164/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3824.6677 - val_loss: 5106.4561\n",
            "Epoch 165/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3818.2385 - val_loss: 5087.8096\n",
            "Epoch 166/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3822.0618 - val_loss: 4983.1377\n",
            "Epoch 167/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3814.9573 - val_loss: 4986.3311\n",
            "Epoch 168/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3804.4111 - val_loss: 5082.6523\n",
            "Epoch 169/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3807.1494 - val_loss: 5011.5312\n",
            "Epoch 170/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3804.3516 - val_loss: 5037.7402\n",
            "Epoch 171/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3805.1333 - val_loss: 5030.1865\n",
            "Epoch 172/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3805.0432 - val_loss: 5065.9385\n",
            "Epoch 173/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3799.8311 - val_loss: 5075.3042\n",
            "Epoch 174/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3806.4578 - val_loss: 5037.0366\n",
            "Epoch 175/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3786.8511 - val_loss: 5099.6855\n",
            "Epoch 176/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3793.1897 - val_loss: 5077.6289\n",
            "Epoch 177/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3797.6255 - val_loss: 5025.0942\n",
            "Epoch 178/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3783.9509 - val_loss: 5008.9937\n",
            "Epoch 179/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3783.8467 - val_loss: 5175.6650\n",
            "Epoch 180/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3796.3198 - val_loss: 5116.2529\n",
            "Epoch 181/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3768.9749 - val_loss: 5102.1333\n",
            "Epoch 182/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3768.8123 - val_loss: 5113.2915\n",
            "Epoch 183/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3782.3320 - val_loss: 5171.8408\n",
            "Epoch 184/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3776.0945 - val_loss: 5190.6157\n",
            "Epoch 185/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3770.8435 - val_loss: 5134.2227\n",
            "Epoch 186/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3780.5923 - val_loss: 5038.8447\n",
            "Epoch 187/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3783.4946 - val_loss: 5065.7266\n",
            "Epoch 188/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3758.6841 - val_loss: 5120.8936\n",
            "Epoch 189/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3762.9175 - val_loss: 5237.0513\n",
            "Epoch 190/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3765.0205 - val_loss: 5135.6421\n",
            "Epoch 191/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 3769.1697 - val_loss: 5128.3013\n",
            "Epoch 192/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 3757.7124 - val_loss: 5128.0371\n",
            "Epoch 193/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3770.4338 - val_loss: 5115.4658\n",
            "Epoch 194/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3766.2532 - val_loss: 5199.2769\n",
            "Epoch 195/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3755.6584 - val_loss: 5085.9717\n",
            "Epoch 196/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3755.4666 - val_loss: 5039.5205\n",
            "Epoch 197/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3754.9033 - val_loss: 5089.9673\n",
            "Epoch 198/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3754.4910 - val_loss: 5045.3525\n",
            "Epoch 199/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3748.1599 - val_loss: 5100.4507\n",
            "Epoch 200/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 3744.9998 - val_loss: 5112.9282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_che_pred_dens.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_pred_dens.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "iZlKtlSmKiwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f08fb2e-7b12-4379-a705-5a9fd0a00613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "468/468 [==============================] - 1s 2ms/step - loss: 5066.6558\n",
            "R^2: 0.689592634485293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict structural features\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y_pore = features[\"poreVolume_cm_3_g_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_pore, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_pred_pore = Sequential()\n",
        "model_che_pred_pore.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_pore.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_pore.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_pred_pore.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_che_pred_pore = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_pred_pore_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_pred_pore = model_che_pred_pore.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_pred_pore])\n",
        "\n",
        "model_che_pred_pore.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_pred_pore.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "g3nRTbFeKySx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d904e201-a8cf-4b5d-a7b2-f386b59189ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 7.5365 - val_loss: 6.6671\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 6.1826 - val_loss: 6.2962\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.9554 - val_loss: 6.0016\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.7815 - val_loss: 5.9826\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.6659 - val_loss: 5.7756\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.5585 - val_loss: 5.8924\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.4900 - val_loss: 5.7751\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.4076 - val_loss: 5.7348\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.3528 - val_loss: 5.9251\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.3234 - val_loss: 5.8840\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 5.2692 - val_loss: 5.6424\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.2602 - val_loss: 5.7593\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.2127 - val_loss: 5.8997\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1998 - val_loss: 5.6621\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1636 - val_loss: 5.6472\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1463 - val_loss: 5.8129\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 5.0928 - val_loss: 5.5605\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0935 - val_loss: 5.5526\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0724 - val_loss: 5.5986\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0612 - val_loss: 5.6821\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0685 - val_loss: 5.6644\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0378 - val_loss: 5.6165\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0219 - val_loss: 5.6236\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0106 - val_loss: 5.8256\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0028 - val_loss: 6.1545\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9741 - val_loss: 5.6541\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9892 - val_loss: 5.5945\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9833 - val_loss: 5.6501\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9532 - val_loss: 5.6993\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9408 - val_loss: 5.7765\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9362 - val_loss: 5.5873\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9267 - val_loss: 5.5642\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9220 - val_loss: 5.7300\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9132 - val_loss: 5.6961\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.9098 - val_loss: 5.7182\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8709 - val_loss: 5.6824\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8761 - val_loss: 5.8570\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8682 - val_loss: 5.7326\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8811 - val_loss: 5.6810\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8735 - val_loss: 5.6484\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8380 - val_loss: 5.7957\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8448 - val_loss: 5.6125\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8331 - val_loss: 5.7177\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8546 - val_loss: 5.6439\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8437 - val_loss: 5.6663\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8269 - val_loss: 5.6544\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8064 - val_loss: 5.7287\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8149 - val_loss: 5.7011\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4.8067 - val_loss: 5.7661\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4.8199 - val_loss: 5.6441\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7933 - val_loss: 5.6052\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7890 - val_loss: 5.6335\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8003 - val_loss: 5.7523\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7869 - val_loss: 5.7125\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7870 - val_loss: 5.7109\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7652 - val_loss: 5.8275\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7596 - val_loss: 5.7935\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7586 - val_loss: 5.7625\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7530 - val_loss: 5.8664\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7251 - val_loss: 5.6640\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7499 - val_loss: 5.7150\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7431 - val_loss: 5.6720\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7284 - val_loss: 5.7164\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7418 - val_loss: 5.6747\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7284 - val_loss: 5.7738\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7144 - val_loss: 5.8132\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7206 - val_loss: 5.7525\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7086 - val_loss: 5.9479\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7168 - val_loss: 5.7397\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7005 - val_loss: 5.8746\n",
            "Epoch 71/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6978 - val_loss: 5.7934\n",
            "Epoch 72/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6970 - val_loss: 5.7942\n",
            "Epoch 73/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6935 - val_loss: 5.8987\n",
            "Epoch 74/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6981 - val_loss: 5.9206\n",
            "Epoch 75/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6764 - val_loss: 5.8360\n",
            "Epoch 76/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6815 - val_loss: 5.8818\n",
            "Epoch 77/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6766 - val_loss: 5.8942\n",
            "Epoch 78/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6702 - val_loss: 5.9478\n",
            "Epoch 79/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6745 - val_loss: 5.8536\n",
            "Epoch 80/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6578 - val_loss: 5.8704\n",
            "Epoch 81/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6491 - val_loss: 6.1325\n",
            "Epoch 82/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4.6668 - val_loss: 6.2003\n",
            "Epoch 83/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6707 - val_loss: 5.9282\n",
            "Epoch 84/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6603 - val_loss: 5.8435\n",
            "Epoch 85/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6503 - val_loss: 5.8377\n",
            "Epoch 86/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6617 - val_loss: 6.0194\n",
            "Epoch 87/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6516 - val_loss: 5.9107\n",
            "Epoch 88/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6438 - val_loss: 5.8323\n",
            "Epoch 89/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6589 - val_loss: 5.8340\n",
            "Epoch 90/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6412 - val_loss: 5.7769\n",
            "Epoch 91/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6257 - val_loss: 5.9169\n",
            "Epoch 92/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6298 - val_loss: 5.9339\n",
            "Epoch 93/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6323 - val_loss: 5.9452\n",
            "Epoch 94/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6113 - val_loss: 5.9853\n",
            "Epoch 95/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6046 - val_loss: 5.9499\n",
            "Epoch 96/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6121 - val_loss: 6.0026\n",
            "Epoch 97/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6122 - val_loss: 5.9283\n",
            "Epoch 98/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6101 - val_loss: 5.8419\n",
            "Epoch 99/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6118 - val_loss: 5.9834\n",
            "Epoch 100/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5999 - val_loss: 5.9316\n",
            "Epoch 101/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5976 - val_loss: 5.9630\n",
            "Epoch 102/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5967 - val_loss: 6.0166\n",
            "Epoch 103/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5834 - val_loss: 6.0932\n",
            "Epoch 104/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5932 - val_loss: 6.0030\n",
            "Epoch 105/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5823 - val_loss: 5.9423\n",
            "Epoch 106/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5871 - val_loss: 5.9316\n",
            "Epoch 107/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5892 - val_loss: 6.0985\n",
            "Epoch 108/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5843 - val_loss: 6.0090\n",
            "Epoch 109/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5803 - val_loss: 6.0350\n",
            "Epoch 110/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5777 - val_loss: 6.1289\n",
            "Epoch 111/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5814 - val_loss: 5.8925\n",
            "Epoch 112/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5661 - val_loss: 6.0849\n",
            "Epoch 113/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5896 - val_loss: 5.9397\n",
            "Epoch 114/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5608 - val_loss: 6.0597\n",
            "Epoch 115/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4.5557 - val_loss: 5.9972\n",
            "Epoch 116/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5705 - val_loss: 6.0159\n",
            "Epoch 117/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5496 - val_loss: 6.0594\n",
            "Epoch 118/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5604 - val_loss: 6.0154\n",
            "Epoch 119/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5677 - val_loss: 6.0000\n",
            "Epoch 120/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5606 - val_loss: 6.0571\n",
            "Epoch 121/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5449 - val_loss: 6.0050\n",
            "Epoch 122/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5393 - val_loss: 6.0697\n",
            "Epoch 123/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5537 - val_loss: 6.0327\n",
            "Epoch 124/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5491 - val_loss: 6.0020\n",
            "Epoch 125/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5457 - val_loss: 6.0077\n",
            "Epoch 126/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5311 - val_loss: 6.0876\n",
            "Epoch 127/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5555 - val_loss: 6.0098\n",
            "Epoch 128/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5304 - val_loss: 6.0893\n",
            "Epoch 129/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5286 - val_loss: 6.0398\n",
            "Epoch 130/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5343 - val_loss: 6.1179\n",
            "Epoch 131/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5265 - val_loss: 6.0005\n",
            "Epoch 132/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5292 - val_loss: 5.9896\n",
            "Epoch 133/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5416 - val_loss: 6.1280\n",
            "Epoch 134/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5301 - val_loss: 6.1267\n",
            "Epoch 135/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5166 - val_loss: 6.0686\n",
            "Epoch 136/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5199 - val_loss: 6.1189\n",
            "Epoch 137/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5195 - val_loss: 6.0529\n",
            "Epoch 138/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5163 - val_loss: 6.3631\n",
            "Epoch 139/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5218 - val_loss: 6.2270\n",
            "Epoch 140/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5262 - val_loss: 6.1545\n",
            "Epoch 141/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4959 - val_loss: 6.1633\n",
            "Epoch 142/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5065 - val_loss: 6.0874\n",
            "Epoch 143/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5002 - val_loss: 6.0870\n",
            "Epoch 144/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5189 - val_loss: 6.1409\n",
            "Epoch 145/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4906 - val_loss: 6.0579\n",
            "Epoch 146/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5005 - val_loss: 6.1218\n",
            "Epoch 147/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4932 - val_loss: 6.2277\n",
            "Epoch 148/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4.4908 - val_loss: 6.2162\n",
            "Epoch 149/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5009 - val_loss: 6.2018\n",
            "Epoch 150/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4973 - val_loss: 6.1770\n",
            "Epoch 151/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4835 - val_loss: 6.3857\n",
            "Epoch 152/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4849 - val_loss: 6.2101\n",
            "Epoch 153/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4974 - val_loss: 6.1259\n",
            "Epoch 154/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4808 - val_loss: 6.1881\n",
            "Epoch 155/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4844 - val_loss: 6.1359\n",
            "Epoch 156/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4724 - val_loss: 6.1937\n",
            "Epoch 157/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4740 - val_loss: 6.1900\n",
            "Epoch 158/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4705 - val_loss: 6.3188\n",
            "Epoch 159/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4766 - val_loss: 6.1832\n",
            "Epoch 160/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4687 - val_loss: 6.1696\n",
            "Epoch 161/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4615 - val_loss: 6.1635\n",
            "Epoch 162/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4570 - val_loss: 6.3631\n",
            "Epoch 163/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4718 - val_loss: 6.2233\n",
            "Epoch 164/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4638 - val_loss: 6.2319\n",
            "Epoch 165/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4545 - val_loss: 6.2593\n",
            "Epoch 166/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4597 - val_loss: 6.2757\n",
            "Epoch 167/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4524 - val_loss: 6.2000\n",
            "Epoch 168/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4547 - val_loss: 6.1658\n",
            "Epoch 169/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4619 - val_loss: 6.1660\n",
            "Epoch 170/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4455 - val_loss: 6.2302\n",
            "Epoch 171/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4585 - val_loss: 6.2703\n",
            "Epoch 172/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4397 - val_loss: 6.3333\n",
            "Epoch 173/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4670 - val_loss: 6.3191\n",
            "Epoch 174/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4346 - val_loss: 6.2466\n",
            "Epoch 175/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4336 - val_loss: 6.2753\n",
            "Epoch 176/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4364 - val_loss: 6.2304\n",
            "Epoch 177/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4443 - val_loss: 6.1894\n",
            "Epoch 178/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4394 - val_loss: 6.2125\n",
            "Epoch 179/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4341 - val_loss: 6.4003\n",
            "Epoch 180/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 4.4318 - val_loss: 6.3230\n",
            "Epoch 181/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 4.4440 - val_loss: 6.2654\n",
            "Epoch 182/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4212 - val_loss: 6.3230\n",
            "Epoch 183/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4098 - val_loss: 6.4884\n",
            "Epoch 184/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4430 - val_loss: 6.3350\n",
            "Epoch 185/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4238 - val_loss: 6.2972\n",
            "Epoch 186/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4262 - val_loss: 6.3559\n",
            "Epoch 187/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4182 - val_loss: 6.4665\n",
            "Epoch 188/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4271 - val_loss: 6.4162\n",
            "Epoch 189/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4143 - val_loss: 6.3488\n",
            "Epoch 190/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4129 - val_loss: 6.3356\n",
            "Epoch 191/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4279 - val_loss: 6.2798\n",
            "Epoch 192/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4202 - val_loss: 6.3651\n",
            "Epoch 193/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4003 - val_loss: 6.4419\n",
            "Epoch 194/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4229 - val_loss: 6.3588\n",
            "Epoch 195/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4083 - val_loss: 6.4583\n",
            "Epoch 196/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4001 - val_loss: 6.3008\n",
            "Epoch 197/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4088 - val_loss: 6.3360\n",
            "Epoch 198/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4135 - val_loss: 6.4313\n",
            "Epoch 199/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4158 - val_loss: 6.3443\n",
            "Epoch 200/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4026 - val_loss: 6.3467\n",
            "468/468 [==============================] - 1s 2ms/step - loss: 5.9282\n",
            "R^2: 0.49523260549563275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict structural features\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y_lisd = features[\"largestIncludedSphereDiameter_A_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_lisd, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_pred_lisd = Sequential()\n",
        "model_che_pred_lisd.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_lisd.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_lisd.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_pred_lisd.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_che_pred_lisd = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_pred_lisd_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_pred_lisd = model_che_pred_lisd.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_pred_lisd])\n",
        "\n",
        "model_che_pred_lisd.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_pred_lisd.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "KKd46OPQ6hH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c016ff0b-2712-4161-9715-6b2e0ac75905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 83.7690 - val_loss: 36.5067\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 34.9347 - val_loss: 32.4039\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 31.4958 - val_loss: 29.7700\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 29.4122 - val_loss: 29.3934\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 27.7371 - val_loss: 28.6005\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 26.8019 - val_loss: 27.5486\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 25.9753 - val_loss: 27.8888\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 25.3745 - val_loss: 26.1254\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 24.8711 - val_loss: 25.4551\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 24.4688 - val_loss: 24.8846\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 23.9752 - val_loss: 25.3401\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 23.7059 - val_loss: 25.3912\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 23.3740 - val_loss: 25.0573\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 23.4389 - val_loss: 25.4645\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 23.2200 - val_loss: 24.6418\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.8353 - val_loss: 24.2764\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.5050 - val_loss: 24.5916\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.4818 - val_loss: 24.7043\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 22.3671 - val_loss: 24.2749\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.1205 - val_loss: 24.2375\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.0169 - val_loss: 24.1813\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.9409 - val_loss: 24.3398\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.7586 - val_loss: 24.0150\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.6129 - val_loss: 25.8713\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.7010 - val_loss: 23.7728\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.3830 - val_loss: 24.5815\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.3606 - val_loss: 23.9430\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.2483 - val_loss: 24.2723\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 21.2075 - val_loss: 23.4454\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.1417 - val_loss: 23.8095\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.0743 - val_loss: 23.9553\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.1489 - val_loss: 23.6982\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.8536 - val_loss: 23.7617\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.9866 - val_loss: 23.7050\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.8326 - val_loss: 23.4938\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 20.7536 - val_loss: 23.8015\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 20.6831 - val_loss: 24.3798\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.6789 - val_loss: 24.4031\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.6294 - val_loss: 23.5103\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.5110 - val_loss: 23.7740\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 20.4370 - val_loss: 23.3645\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.4180 - val_loss: 23.7564\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.3870 - val_loss: 24.2828\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.3115 - val_loss: 24.3741\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.2839 - val_loss: 23.4353\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.3126 - val_loss: 24.4279\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.2220 - val_loss: 23.4251\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.1466 - val_loss: 23.7958\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.1494 - val_loss: 23.5419\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.1136 - val_loss: 23.5458\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.9468 - val_loss: 23.6509\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.1122 - val_loss: 23.5273\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.0077 - val_loss: 24.1543\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.8189 - val_loss: 23.6477\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.9204 - val_loss: 23.3924\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.8393 - val_loss: 23.4588\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.8147 - val_loss: 24.5195\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.7484 - val_loss: 23.4825\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.7445 - val_loss: 24.5257\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.7428 - val_loss: 23.9306\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.5744 - val_loss: 24.0286\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.6633 - val_loss: 24.0544\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.7386 - val_loss: 25.1647\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.6020 - val_loss: 24.1479\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.5738 - val_loss: 23.7480\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.5535 - val_loss: 23.4423\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.5386 - val_loss: 23.8369\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.5590 - val_loss: 24.6961\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 19.4756 - val_loss: 24.2307\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 19.4879 - val_loss: 24.4466\n",
            "Epoch 71/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.4250 - val_loss: 24.5215\n",
            "Epoch 72/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.3812 - val_loss: 23.4928\n",
            "Epoch 73/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.3812 - val_loss: 23.7845\n",
            "Epoch 74/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.3270 - val_loss: 23.8792\n",
            "Epoch 75/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.2919 - val_loss: 23.6682\n",
            "Epoch 76/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.2379 - val_loss: 23.8659\n",
            "Epoch 77/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.3054 - val_loss: 24.7272\n",
            "Epoch 78/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.1656 - val_loss: 24.0512\n",
            "Epoch 79/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.2728 - val_loss: 23.7152\n",
            "Epoch 80/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.1666 - val_loss: 23.8425\n",
            "Epoch 81/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.1027 - val_loss: 24.4331\n",
            "Epoch 82/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0568 - val_loss: 24.1954\n",
            "Epoch 83/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0908 - val_loss: 24.0913\n",
            "Epoch 84/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0931 - val_loss: 24.1036\n",
            "Epoch 85/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0310 - val_loss: 23.9995\n",
            "Epoch 86/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.1301 - val_loss: 23.9479\n",
            "Epoch 87/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9595 - val_loss: 23.8735\n",
            "Epoch 88/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0604 - val_loss: 23.7424\n",
            "Epoch 89/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0768 - val_loss: 24.1464\n",
            "Epoch 90/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.0634 - val_loss: 24.5403\n",
            "Epoch 91/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9532 - val_loss: 24.3081\n",
            "Epoch 92/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9295 - val_loss: 25.5096\n",
            "Epoch 93/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9234 - val_loss: 24.2026\n",
            "Epoch 94/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9934 - val_loss: 24.0789\n",
            "Epoch 95/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9183 - val_loss: 24.3486\n",
            "Epoch 96/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.8888 - val_loss: 26.7753\n",
            "Epoch 97/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9115 - val_loss: 24.3418\n",
            "Epoch 98/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.8247 - val_loss: 23.5935\n",
            "Epoch 99/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.7672 - val_loss: 24.4193\n",
            "Epoch 100/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9119 - val_loss: 23.9818\n",
            "Epoch 101/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.7031 - val_loss: 24.3825\n",
            "Epoch 102/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 18.8631 - val_loss: 24.2314\n",
            "Epoch 103/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 18.8007 - val_loss: 23.9844\n",
            "Epoch 104/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6674 - val_loss: 24.0822\n",
            "Epoch 105/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.7628 - val_loss: 23.9400\n",
            "Epoch 106/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6999 - val_loss: 24.4387\n",
            "Epoch 107/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6520 - val_loss: 24.1620\n",
            "Epoch 108/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6937 - val_loss: 24.2001\n",
            "Epoch 109/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6838 - val_loss: 25.0512\n",
            "Epoch 110/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6225 - val_loss: 25.7599\n",
            "Epoch 111/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6552 - val_loss: 24.5541\n",
            "Epoch 112/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5981 - val_loss: 24.3517\n",
            "Epoch 113/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6498 - val_loss: 24.0650\n",
            "Epoch 114/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5922 - val_loss: 24.0056\n",
            "Epoch 115/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5033 - val_loss: 24.3612\n",
            "Epoch 116/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4828 - val_loss: 24.1476\n",
            "Epoch 117/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4497 - val_loss: 23.8995\n",
            "Epoch 118/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5752 - val_loss: 24.1175\n",
            "Epoch 119/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4435 - val_loss: 25.2827\n",
            "Epoch 120/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5257 - val_loss: 24.0490\n",
            "Epoch 121/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4347 - val_loss: 25.5351\n",
            "Epoch 122/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5254 - val_loss: 24.2267\n",
            "Epoch 123/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3423 - val_loss: 24.0551\n",
            "Epoch 124/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3507 - val_loss: 24.6038\n",
            "Epoch 125/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3578 - val_loss: 24.6502\n",
            "Epoch 126/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3712 - val_loss: 25.1015\n",
            "Epoch 127/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4919 - val_loss: 24.2503\n",
            "Epoch 128/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4090 - val_loss: 24.9825\n",
            "Epoch 129/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4624 - val_loss: 24.2255\n",
            "Epoch 130/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3950 - val_loss: 24.1848\n",
            "Epoch 131/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2955 - val_loss: 25.2315\n",
            "Epoch 132/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3774 - val_loss: 25.0559\n",
            "Epoch 133/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2881 - val_loss: 24.4595\n",
            "Epoch 134/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3963 - val_loss: 24.5642\n",
            "Epoch 135/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 18.2536 - val_loss: 24.4028\n",
            "Epoch 136/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 18.2156 - val_loss: 25.9806\n",
            "Epoch 137/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2039 - val_loss: 24.9859\n",
            "Epoch 138/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2321 - val_loss: 24.9157\n",
            "Epoch 139/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2415 - val_loss: 25.0139\n",
            "Epoch 140/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1987 - val_loss: 24.5654\n",
            "Epoch 141/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2292 - val_loss: 24.6045\n",
            "Epoch 142/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0921 - val_loss: 24.6665\n",
            "Epoch 143/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1927 - val_loss: 26.1507\n",
            "Epoch 144/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1021 - val_loss: 24.7964\n",
            "Epoch 145/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1609 - val_loss: 25.0838\n",
            "Epoch 146/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0809 - val_loss: 24.6862\n",
            "Epoch 147/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0959 - val_loss: 24.6670\n",
            "Epoch 148/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0918 - val_loss: 24.1302\n",
            "Epoch 149/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1692 - val_loss: 24.7368\n",
            "Epoch 150/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1800 - val_loss: 24.8552\n",
            "Epoch 151/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0178 - val_loss: 25.1377\n",
            "Epoch 152/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0465 - val_loss: 24.3438\n",
            "Epoch 153/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0392 - val_loss: 25.0662\n",
            "Epoch 154/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9701 - val_loss: 24.5268\n",
            "Epoch 155/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0273 - val_loss: 25.0788\n",
            "Epoch 156/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0567 - val_loss: 25.2004\n",
            "Epoch 157/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9916 - val_loss: 24.8996\n",
            "Epoch 158/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9235 - val_loss: 24.8482\n",
            "Epoch 159/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9611 - val_loss: 24.4113\n",
            "Epoch 160/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9950 - val_loss: 24.6730\n",
            "Epoch 161/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9034 - val_loss: 25.8216\n",
            "Epoch 162/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8675 - val_loss: 25.0188\n",
            "Epoch 163/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9779 - val_loss: 24.9414\n",
            "Epoch 164/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9269 - val_loss: 25.3296\n",
            "Epoch 165/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9323 - val_loss: 25.3600\n",
            "Epoch 166/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8565 - val_loss: 24.9839\n",
            "Epoch 167/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8540 - val_loss: 24.8902\n",
            "Epoch 168/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 17.7957 - val_loss: 24.9219\n",
            "Epoch 169/200\n",
            "1122/1122 [==============================] - 4s 3ms/step - loss: 17.9036 - val_loss: 24.5225\n",
            "Epoch 170/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8710 - val_loss: 24.7962\n",
            "Epoch 171/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7568 - val_loss: 24.5787\n",
            "Epoch 172/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8417 - val_loss: 24.9481\n",
            "Epoch 173/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8581 - val_loss: 25.1850\n",
            "Epoch 174/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8173 - val_loss: 25.7070\n",
            "Epoch 175/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8180 - val_loss: 25.2323\n",
            "Epoch 176/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8395 - val_loss: 25.9600\n",
            "Epoch 177/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7937 - val_loss: 24.8540\n",
            "Epoch 178/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7846 - val_loss: 24.8131\n",
            "Epoch 179/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7790 - val_loss: 24.9706\n",
            "Epoch 180/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7880 - val_loss: 25.1359\n",
            "Epoch 181/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7731 - val_loss: 24.9845\n",
            "Epoch 182/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6925 - val_loss: 25.3489\n",
            "Epoch 183/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7406 - val_loss: 24.9092\n",
            "Epoch 184/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7952 - val_loss: 25.6060\n",
            "Epoch 185/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7169 - val_loss: 25.1830\n",
            "Epoch 186/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7718 - val_loss: 25.3792\n",
            "Epoch 187/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5946 - val_loss: 25.2154\n",
            "Epoch 188/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6575 - val_loss: 24.7371\n",
            "Epoch 189/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6268 - val_loss: 24.8552\n",
            "Epoch 190/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6630 - val_loss: 25.0380\n",
            "Epoch 191/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6209 - val_loss: 25.0097\n",
            "Epoch 192/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5635 - val_loss: 25.2285\n",
            "Epoch 193/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6788 - val_loss: 25.3452\n",
            "Epoch 194/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6113 - val_loss: 25.1901\n",
            "Epoch 195/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5769 - val_loss: 25.1142\n",
            "Epoch 196/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5828 - val_loss: 26.4736\n",
            "Epoch 197/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5426 - val_loss: 25.8040\n",
            "Epoch 198/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5405 - val_loss: 25.1774\n",
            "Epoch 199/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6378 - val_loss: 26.0332\n",
            "Epoch 200/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5517 - val_loss: 25.5516\n",
            "468/468 [==============================] - 1s 2ms/step - loss: 25.4528\n",
            "R^2: 0.8292705669839371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict structural features\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y_lfsd = features[\"largestFreeSphereDiameter_A_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_lfsd, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_pred_lfsd = Sequential()\n",
        "model_che_pred_lfsd.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_lfsd.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_lfsd.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_pred_lfsd.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_che_pred_lfsd = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_pred_lfsd_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_pred_lfsd = model_che_pred_lfsd.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_pred_lfsd])\n",
        "\n",
        "model_che_pred_lfsd.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_pred_lfsd.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "3semtgiK65qO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b22983-e1b8-48ac-b73b-a24db09f8362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 60.6561 - val_loss: 32.3185\n",
            "Epoch 2/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 29.8532 - val_loss: 29.0013\n",
            "Epoch 3/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 26.7906 - val_loss: 26.3976\n",
            "Epoch 4/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 24.8939 - val_loss: 24.3344\n",
            "Epoch 5/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 23.8363 - val_loss: 25.5401\n",
            "Epoch 6/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.9597 - val_loss: 22.9804\n",
            "Epoch 7/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 22.3915 - val_loss: 24.0725\n",
            "Epoch 8/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.9142 - val_loss: 23.4576\n",
            "Epoch 9/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 21.4761 - val_loss: 22.4514\n",
            "Epoch 10/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 21.1571 - val_loss: 22.2785\n",
            "Epoch 11/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.9478 - val_loss: 22.6374\n",
            "Epoch 12/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.7559 - val_loss: 21.9267\n",
            "Epoch 13/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.5026 - val_loss: 21.6499\n",
            "Epoch 14/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.2593 - val_loss: 21.3742\n",
            "Epoch 15/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 20.0734 - val_loss: 21.5929\n",
            "Epoch 16/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.9306 - val_loss: 22.7928\n",
            "Epoch 17/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.7768 - val_loss: 21.5071\n",
            "Epoch 18/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 19.6564 - val_loss: 21.2232\n",
            "Epoch 19/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.5862 - val_loss: 22.2134\n",
            "Epoch 20/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.4497 - val_loss: 22.1895\n",
            "Epoch 21/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.2551 - val_loss: 21.9178\n",
            "Epoch 22/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.2909 - val_loss: 21.7728\n",
            "Epoch 23/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 19.1147 - val_loss: 21.6977\n",
            "Epoch 24/200\n",
            "1122/1122 [==============================] - 5s 4ms/step - loss: 19.0014 - val_loss: 21.0009\n",
            "Epoch 25/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.9008 - val_loss: 21.6273\n",
            "Epoch 26/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.8764 - val_loss: 21.5014\n",
            "Epoch 27/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 18.7645 - val_loss: 20.9197\n",
            "Epoch 28/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.7820 - val_loss: 20.7416\n",
            "Epoch 29/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6256 - val_loss: 21.4313\n",
            "Epoch 30/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.6113 - val_loss: 21.0941\n",
            "Epoch 31/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5692 - val_loss: 21.8386\n",
            "Epoch 32/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.5054 - val_loss: 20.9321\n",
            "Epoch 33/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.3282 - val_loss: 20.9852\n",
            "Epoch 34/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.4523 - val_loss: 21.1774\n",
            "Epoch 35/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2896 - val_loss: 21.4561\n",
            "Epoch 36/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2315 - val_loss: 22.1907\n",
            "Epoch 37/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.2209 - val_loss: 21.4652\n",
            "Epoch 38/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.1542 - val_loss: 21.5835\n",
            "Epoch 39/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0958 - val_loss: 20.9275\n",
            "Epoch 40/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0345 - val_loss: 20.9583\n",
            "Epoch 41/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0227 - val_loss: 21.1745\n",
            "Epoch 42/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 18.0475 - val_loss: 20.8712\n",
            "Epoch 43/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.9271 - val_loss: 20.9973\n",
            "Epoch 44/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8904 - val_loss: 20.8863\n",
            "Epoch 45/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8827 - val_loss: 21.0836\n",
            "Epoch 46/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8389 - val_loss: 24.4318\n",
            "Epoch 47/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 17.8285 - val_loss: 20.7078\n",
            "Epoch 48/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.8014 - val_loss: 21.4012\n",
            "Epoch 49/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7821 - val_loss: 21.3617\n",
            "Epoch 50/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.7089 - val_loss: 22.2854\n",
            "Epoch 51/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6497 - val_loss: 21.0565\n",
            "Epoch 52/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6511 - val_loss: 21.0424\n",
            "Epoch 53/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6347 - val_loss: 21.9245\n",
            "Epoch 54/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.6343 - val_loss: 21.3327\n",
            "Epoch 55/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5300 - val_loss: 21.2411\n",
            "Epoch 56/200\n",
            "1122/1122 [==============================] - 4s 4ms/step - loss: 17.5818 - val_loss: 21.3406\n",
            "Epoch 57/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.5769 - val_loss: 22.4366\n",
            "Epoch 58/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.4867 - val_loss: 21.1527\n",
            "Epoch 59/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.4030 - val_loss: 21.2878\n",
            "Epoch 60/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.4716 - val_loss: 21.6339\n",
            "Epoch 61/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.3882 - val_loss: 21.0724\n",
            "Epoch 62/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.4169 - val_loss: 21.2702\n",
            "Epoch 63/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.3497 - val_loss: 21.3347\n",
            "Epoch 64/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.3306 - val_loss: 21.1681\n",
            "Epoch 65/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.2811 - val_loss: 22.5793\n",
            "Epoch 66/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.2654 - val_loss: 21.2045\n",
            "Epoch 67/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.2475 - val_loss: 21.4888\n",
            "Epoch 68/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.2478 - val_loss: 21.2646\n",
            "Epoch 69/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.1446 - val_loss: 21.2013\n",
            "Epoch 70/200\n",
            "1122/1122 [==============================] - 3s 3ms/step - loss: 17.1724 - val_loss: 21.4508\n",
            "Epoch 71/200\n",
            " 258/1122 [=====>........................] - ETA: 2s - loss: 17.3435"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict structural features\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y_lisafspd = features[\"largestIncludedSphereAlongFreeSpherePathDiameter_A_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_lisafspd, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_pred_lisafspd = Sequential()\n",
        "model_che_pred_lisafspd.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_lisafspd.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_lisafspd.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_pred_lisafspd.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_che_pred_lisafspd = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_pred_lisafspd_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_pred_lisafspd = model_che_pred_lisafspd.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_pred_lisafspd])\n",
        "\n",
        "model_che_pred_lisafspd.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_pred_lisafspd.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ZHWt1ru07D-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# composition only to predict structural features\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "y_void = features[\"voidFraction_widom_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_void, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "model_che_pred_void = Sequential()\n",
        "model_che_pred_void.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_void.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_che_pred_void.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_che_pred_void.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.00003, clipnorm = 0.5))\n",
        "\n",
        "checkpoint_che_pred_void = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/che_pred_void_co2q.h5\", save_best_only = True)\n",
        "\n",
        "fit_che_pred_void = model_che_pred_void.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_che_pred_void])\n",
        "\n",
        "model_che_pred_void.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_che_pred_void.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "7Hm_P25g7Z6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load models\n",
        "\n",
        "model_che_pred_dens = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_dens_co2q.h5\")\n",
        "model_che_pred_pore = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_pore_co2q.h5\")\n",
        "model_che_pred_lisd = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_lisd_co2q.h5\")\n",
        "model_che_pred_lfsd = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_lfsd_co2q.h5\")\n",
        "model_che_pred_lisafspd = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_lisafspd_co2q.h5\")\n",
        "#model_che_pred_void = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_void_co2q.h5\")\n",
        "\n",
        "# scale\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# predictions of structural features\n",
        "\n",
        "y_pred_dens = model_che_pred_dens.predict(x_scaled)\n",
        "y_pred_pore = model_che_pred_pore.predict(x_scaled)\n",
        "y_pred_lisd = model_che_pred_lisd.predict(x_scaled)\n",
        "y_pred_lfsd = model_che_pred_lfsd.predict(x_scaled)\n",
        "y_pred_lisafspd = model_che_pred_lisafspd.predict(x_scaled)\n",
        "#y_pred_void = model_che_pred_void.predict(x_scaled)"
      ],
      "metadata": {
        "id": "9D86m1lb7zOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put in new pandas data frame\n",
        "\n",
        "new_features = features\n",
        "new_features[\"dens\"] = y_pred_dens\n",
        "new_features[\"pore\"] = y_pred_pore\n",
        "new_features[\"lisd\"] = y_pred_lisd\n",
        "new_features[\"lfsd\"] = y_pred_lfsd\n",
        "new_features[\"lisafspd\"] = y_pred_lisafspd\n",
        "#new_features[\"void\"] = y_pred_void"
      ],
      "metadata": {
        "id": "ZQ1hO4kMLN8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RmOH0CPiKHWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new predictions of CO2 and CH4\n",
        "\n",
        "x = new_features\n",
        "y = properties[\"absoluteMethaneUptakeHighP_mol_kg_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# from pervious HP training\n",
        "\n",
        "model_all_str_che_ch4_new = Sequential()\n",
        "model_all_str_che_ch4_new.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_ch4_new.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_ch4_new.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_all_str_che_ch4_new.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_all_str_che_ch4_new = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/all_str_che_ch4_new.h5\", save_best_only = True)\n",
        "\n",
        "fit_all_str_che_ch4_new = model_all_str_che_ch4_new.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_all_str_che_ch4_new])\n",
        "\n",
        "model_all_str_che_ch4_new.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_all_str_che_ch4_new.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "i4DzlIqpJ_0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# composition and structure to predict CO2Qst using NN\n",
        "\n",
        "x = new_features\n",
        "y = properties[\"CO2Qst_kJ_mol_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# from pervious HP training\n",
        "\n",
        "model_all_str_che_co2_new = Sequential()\n",
        "model_all_str_che_co2_new.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_co2_new.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_co2_new.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_all_str_che_co2_new.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_all_str_che_co2_new = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/all_str_che_co2_new.h5\", save_best_only = True)\n",
        "\n",
        "fit_all_str_che_co2_new = model_all_str_che_co2_new.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_all_str_che_co2_new])"
      ],
      "metadata": {
        "id": "aLQBofZwNmhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_all_str_che_co2_new.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_all_str_che_co2_new.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "SeoLlhjBOSDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch normalization test\n",
        "\n",
        "features = pd.read_csv(\"gdrive/My Drive/cofs/combined_features2.csv\")\n",
        "properties = pd.read_csv('gdrive/My Drive/cofs/properties.csv')\n",
        "\n",
        "# load models\n",
        "\n",
        "model_che_pred_dens = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_dens_co2q.h5\")\n",
        "model_che_pred_pore = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_pore_co2q.h5\")\n",
        "model_che_pred_lisd = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_lisd_co2q.h5\")\n",
        "model_che_pred_lfsd = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_lfsd_co2q.h5\")\n",
        "model_che_pred_lisafspd = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_lisafspd_co2q.h5\")\n",
        "#model_che_pred_void = keras.models.load_model(\"gdrive/My Drive/cofs/che_pred_void_co2q.h5\")\n",
        "\n",
        "# scale\n",
        "\n",
        "x = features.drop(['density_kg_m_3_', 'poreVolume_cm_3_g_',\n",
        "       'largestIncludedSphereDiameter_A_', 'largestFreeSphereDiameter_A_',\n",
        "       'largestIncludedSphereAlongFreeSpherePathDiameter_A_',\n",
        "       'voidFraction_widom_'], axis = 1)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x)\n",
        "\n",
        "# predictions of structural features\n",
        "\n",
        "y_pred_dens = model_che_pred_dens.predict(x_scaled)\n",
        "y_pred_pore = model_che_pred_pore.predict(x_scaled)\n",
        "y_pred_lisd = model_che_pred_lisd.predict(x_scaled)\n",
        "y_pred_lfsd = model_che_pred_lfsd.predict(x_scaled)\n",
        "y_pred_lisafspd = model_che_pred_lisafspd.predict(x_scaled)\n",
        "#y_pred_void = model_che_pred_void.predict(x_scaled)\n",
        "\n",
        "# put in new pandas data frame\n",
        "\n",
        "new_features = features\n",
        "new_features[\"dens\"] = y_pred_dens\n",
        "new_features[\"pore\"] = y_pred_pore\n",
        "new_features[\"lisd\"] = y_pred_lisd\n",
        "new_features[\"lfsd\"] = y_pred_lfsd\n",
        "new_features[\"lisafspd\"] = y_pred_lisafspd\n",
        "#new_features[\"void\"] = y_pred_void\n",
        "\n",
        "# new predictions of CO2 and CH4\n",
        "\n",
        "x = new_features\n",
        "y = properties[\"absoluteMethaneUptakeHighP_mol_kg_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# from pervious HP training\n",
        "\n",
        "model_all_str_che_ch4_new = Sequential()\n",
        "model_all_str_che_ch4_new.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_ch4_new.add(BatchNormalization())\n",
        "model_all_str_che_ch4_new.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_ch4_new.add(BatchNormalization())\n",
        "model_all_str_che_ch4_new.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_all_str_che_ch4_new.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_all_str_che_ch4_new = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/all_str_che_ch4_new.h5\", save_best_only = True)\n",
        "\n",
        "fit_all_str_che_ch4_new = model_all_str_che_ch4_new.fit(x_train, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_all_str_che_ch4_new])\n",
        "\n",
        "model_all_str_che_ch4_new.evaluate(x_test, y_test)\n",
        "\n",
        "y_pred = model_all_str_che_ch4_new.predict(x_test)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "61CSvyWuEjUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CO2 with dropout\n",
        "\n",
        "# composition and structure to predict CO2Qst using NN\n",
        "\n",
        "x = new_features\n",
        "y = properties[\"CO2Qst_kJ_mol_\"]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# from pervious HP training\n",
        "\n",
        "model_all_str_che_co2_new_do = Sequential()\n",
        "model_all_str_che_co2_new_do.add(Dense(372, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_co2_new_do.add(Dense(400, activation = LeakyReLU(alpha=0.3)))\n",
        "model_all_str_che_co2_new_do.add(Dense(1, activation = LeakyReLU(alpha=0.3)))\n",
        "\n",
        "model_all_str_che_co2_new_do.compile(loss='mean_squared_error', optimizer = keras.optimizers.Adam(learning_rate = 0.0003))\n",
        "\n",
        "checkpoint_all_str_che_co2_new = keras.callbacks.ModelCheckpoint(\"gdrive/My Drive/cofs/all_str_che_co2_new.h5\", save_best_only = True)\n",
        "\n",
        "fit_all_str_che_co2_new = model_all_str_che_co2_new.fit(x_train_scaled, y_train, epochs = 200, validation_split = 0.2, callbacks = [checkpoint_all_str_che_co2_new])\n",
        "\n",
        "model_all_str_che_co2_new.evaluate(x_test_scaled, y_test)\n",
        "\n",
        "y_pred = model_all_str_che_co2_new.predict(x_test_scaled)\n",
        "print('R^2:', metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "NOuPjjTNiU3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9d30qtl9OFXS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}